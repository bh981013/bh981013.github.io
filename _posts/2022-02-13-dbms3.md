---
title: "3.buffer management"
tags: 
    - CS
    - DBMS
    - project
    - b+tree
    - database
categories: 
    - DBMS
comments: true
---

# Buffer가 무엇인가요?

버퍼... 처음 버퍼를 들었을 땐 버퍼링? 뭐 이런 단어 정도가 생각났다(근데 연관성이 있었음). 버퍼가 도대체 무엇일까?<br/><br/>

버퍼는 임시 저장공간이라고 볼 수있다. 장치 사이의 속도 차를 상쇄시켜주는 역할을 한다.<br/><br/>

## 버퍼를 왜 써야 할까

이전 게시물에서 disk-based b+tree를 어떻게 구현해야 하는 지 알아보았다. 하지만 b+ tree가 disk와 직접적으로 맞닿아 작업이 일어나면, 속도가 상당히 느려진다. disk I/O는 컴퓨터 작업 중 가장 느린 작업중 하나이기 때문이다. 따라서 __버퍼__ 라는것을 메모리에 만들어서, b+ tree 작업과 disk의 속도차를 메인 메모리를 활용해 줄이고자 하는 것이다. <br/><br/>

## 버퍼 vs 캐시

버퍼에 대해 알아보면서, 캐시와의 차이점이 궁금해졌다. 왜냐면 버퍼와 캐시 모두 속도차를 줄이기 위해 존재하는 데, 언제 구분해서 사용할까?

- 공통점: 버퍼와 캐시 모두 기기간의 속도차를 어떻게하면 줄일 수 있을까? 에 대한 고민에서 나왔다. 매우 속도가 빠른 장치(예: CPU)와 매우 속도가 느린 장치(예: 디스크)의 간격을 줄여주는 역할을 한다.

- 차이점
    - 버퍼: 빠른게 작업하는 장치에서 느린 장치로 데이터를 전달할 때, 빠른 장치는 느린 장치를 기다려 줄 수 없다. 빠른 장치는 그 시간에 엄청나게 많은 일을 할 수 있기 때문이다! 그래서 중간정도 빠른 버퍼라는곳에 임시로 담아서 느린 장치가 알아서 천천히 가져가도록 한다. 그동안 빠른 장치는 일을 할수 있다!<br/>
    예) 프린트를 할때 프린트 할 내용에 대한 정보를 버퍼에 담아둔다.
    
    - 캐시: 빠른 장치는 느린 장치와 데이터를 계속 주고받게 되면, 작업이 비효율적이게 된다. 따라서 빠른 장치는 그나마 덜 느린 장치에 임시로 데이터를 주고받는다. 만약 그 임시 장치에 원하는 데이터가 없으면, 그때서야 느린 장치에 가서 데이터를 가져온다. 느린장치와 직접 소통하는것보단, 그래도 빠르니까!<br/><br/>

사실 우리가 구현하고자 하는 b+ tree의 버퍼는 캐시라고 하는 것이 보다 정확할것이다. 하지만 둘 다 모두 속도를 빠르게 한다는 공통점이 있기 때문에, 섞어서 사용하기도 하는 것 같다(교수님들 조차 엄밀히 구분하시지 않으셨다).<br/><br/>

# Buffer mangement

그럼 이제부터 disk-based b+ tree에서 버퍼를 어떻게 활용하는 지 알아보자.<br/><br/>

## 버퍼의 생성

이전 게시물에서 설명했듯이, 디스크의 파일에서 관리하는 database의 page는 4096byte였다. 이 page들을 메모리에 임시로 저장하기 위해서는, 프로그램이 실행되고 전역변수로 4096byte의 Array를 선언하게 되면, 해당 리스트가 버퍼의 역할을 수행할 수 있다.<br/><br/>

## 버퍼의 관리

이렇게 디스크의 page들을 buffer에 올려놓고, b+ tree 의 여러 삽입/삭제 작업을 buffer가 있는 메모리 위에서 수행한 후, 모든 작업이 종료될 떄 다시 버퍼에 쓰기만 하면 매우 간단하다. 하지만 여기엔 __치명적인 오류__ 가 있다. <u>메모리는 디스크 만큼 크지 않다는 것</u>이다. 즉, 디스크의 모든 페이지가 메모리 위에 올라올 수 없으므로, 메모리에 올릴 페이지를 __선택__ 해야 한다는 것이다.<br/><br/>

> 그럼 어떤 기준으로 메모리에 올릴 페이지를 선택하는 것이 좋을까? 

당연히, 가장 많이 사용되는 페이지를 선택해서 메모리에 올려놓는 것이 좋다. 가장 많이 사용되는 페이지의 접근 횟수가 가장 많으므로, 접근 속도가 빠른 메모리에 미리 올려놓으면 속도에서 큰 이점을 볼 수 있을 것이다.

> 그럼, 가장 많이 사용되는 페이지가 무엇일까?

사실 이건 모른다. 그 누구도 미래를 알 수는 없기 때문이다. 하지만 예측할 수는 있다. 그동안의 경험을 미루어보아, 가장 많이 사용될 것 같은 페이지를 예상하는 알고리즘들이 있다.<br/><br/>

## 페이지 교체 알고리즘

- FIFO(First In, First Out)

    - 페이지를 교체할 때, 가장 합리적인 알고리즘이다. 먼저왔으면 먼저 나가는 것이 인지상정!

    - 하지만, 가끔 아이러니한 상황이 발생한다. 만약 버퍼의 크기가 커진다면, 버퍼에 들어갈 수 있는 페이지가 많아지므로 페이지의 교체가 덜 일어나야 할 것이다. 하지만 특수한 경우엔 오히려 페이지의 교체가 더 많아진다. 이를 __Belady's anomaly__ 라고 한다.

- LFU(Least Frequently Used)

    - 가장 적게 사용된 페이지를 교체시키는 알고리즘이다.

    - 가장 최근에 교체된 페이지가 교체될 가능성이 크다.

- MFU(Most Frequentlu Used)

    - 가장 많이 사용된 페이지를 교체시키는 알고리즘이다. 

    - 지금까지 많이 사용했으니까, 이젠 더이상 사용 안할거야~ 라는 원칙에서 생겨난 알고리즘이다.

- LRU(Least Recently Used)

    - 사용한지 가장 오래된 페이지를 교체시키는 알고리즘이다.

    - 일반적으로 가장 효율적인 알고리즘임이 알려져 있다.

이렇듯 다양한 원칙에서 생겨난 페이지 교체에 관한 여러 알고리즘이 존재한다. 각각 나름대로 합리적인 원칙에서 생겨난 알고리즘이기 때문에, 어떤 알고리즘이 더 좋고, 어떤 알고리즘이 더 나쁘다고 할 수는 없다. 주어진 상황과 조건에 따라 더 좋은 알고리즘이 다른 것이다.<br/><br/>

우리는 여기서 __LRU알고리즘__ 으로 버퍼에서 교체할 페이지를 선정한다. 일반적인 상황에서 가장 성능이 좋다고 알려져 있기 때문이다. 그럼 LRU알고리즘을 어떻게 구현할 수 있는 지 여러 방법에 대해 알아보자.<br/><br/>

# LRU 알고리즘

LRU 알고리즘은 __사용한지 가장 오래된 페이지를 교체하는 것__ 이라고 설명했다. 그럼 가장 오래되었음을 어떤 방식으로 보장할 수 있을까? 그 방법에는 여러가지가 있다. 이는 운영체제의 가상메모리에 대해 공부할 때에도 중요함으로, 여기서 조금 더 자세히 알아보자.<br/><br/>

## 카운터를 활용

- CPU에는 카운터라는 것이 존재한다. 일정 단위로 숫자가 증가하는데, 페이지에 접근할 때 마다 해당 페이지에 시간을 기록해 두는 것이다.

- 만약 페이지의 교체가 필요하면, 버퍼에 있는 페이지 중 시간이 가장 빠른 페이지를 교체시킨다.

- But! 이것은 시간을 기록하는 메모리, 가장 이른 시간 기록을 찾는 것, 등 너무 큰 오버헤드가 발생한다....

## Double linked list 활용

- page들을 double linked list로 연결 시킨 후, 특정 페이지에 접근하게 되면 그 페이지를 페이지list의 가장 앞으로 옮기는 것이다.

- 그러면 가장 뒤에 있는 페이지가 참조한 지 가장 오래되었다고 판단하고, 가장 뒤에 있는 페이지를 교체시킨다.

## Reference bit

- 특정 bit를 페이지에 추가한다. 이 비트는 접근될 때 1이 된다.

- 이 비트는 주기적으로 0 으로 바꾼다. 즉 접근이 안되었으면 0으로 남아 있을 확률이 높다.

- 이 방법은 매우 단순하지만, 그만큼 부정확하다.

## Additional Reference bit

- 비트가 한개가 아닌 8개를 활용한다.

- 특정 주기로 비트를 0으로 바꾸는것이 아닌, 왼쪽으로 shift 한다.<br/>
예) 00100100 -> 0001010

- 만약 특정 페이지에 접근 시, 가장 상위 비트를 1로 바꾼다.<br/>
예) 00001111 -> 10001111

- 비트가 표현하는 숫자의 크기가 작을수록 접근한 지 오래된 페이지이므로, 교체한다.
<br/><br/>

우리는 Double linked list를 활용한 알고리즘을 사용할 것이다. 이 역시 무엇이 좋고 나쁘다고 할 수없다. 상황에 적절한 알고리즘이 있는 것이다.
<br/><br/>

# 버퍼에서의 페이지 교체

이제 버퍼에서 페이지가 교체될 때 고려해야 할 점들을 알아보자.<br/><br/>


## 해당 페이지를 교체시켜도 될까?

버퍼의 특정 페이지가 희생양이 되어 교체되고자 한다. 이때 __해당 페이지가 만약 내가 진행 중인 작업에 활용되는 페이지라면__? 예를들어 두 페이지를 합치려고 첫번째 페이지를 읽어드리고, 두번째 페이지를 읽었는데, 갑자기 첫번째 페이지가 버퍼에서 사라진다면? 

> 매우 당황스러울 것이다...!

이런 상황을 피하기 위해서, 현재 <u>중요한 페이지는 교체시키지 말라</u>고 알려줄 필요가 있다. 그래서 사용하는것이 __pin__ 이다. 어떤 페이지를 pin 시키면, 해당 페이지는 교체시키지 말라는 뜻이다. 따라서 다음 희생양을 찾아야 한다.

> pinning을 통해 그러한 상황을 피하자!


## 해당 페이지를 바로 교체시켜도 될까?

만약 희생양이 된 페이지가 교체당하기로 결정되었다면, 그냥 그 자리에 disk에서 페이지가 올라와도 될까? 아마 그러면 안될것이다..!<br/><br/>

B+ tree의 삽입, 삭제 작업이 끝난 후, 그 결과를 다시 메모리에 저장된 버퍼에 썼을 것이다. 따라서 만약 버퍼상의 페이지가 변화가 있었으면, 다시 디스크에 쓰는 작업이 필요하다. 그것이 바로 dirty bit의 역할이다.

> dirty bit를 통해 해당 페이지를 다시 disk에 쓸지 여부를 결정한다.

이제 모든 준비가 끝났다. 그럼 버퍼를 어떻게 구현하면 좋을 지 알아보자!<br/><br/>

# 버퍼의 구현

![buffer](https://bh981013.github.io/images/2022-02-13/2022-02-13-buffer)

- frame: disk상의 page에 해당한다.

- table id: 어떤 테이블에 포함된 페이지인지를 결정한다. 테이블을 여러개 접근할 경우, 파일은 구분되어 있지만 메모리상에선 섞여있을 것이므로, 어떤 파일출신인지 알려주는 변수이다.

- pagenum: 해당 frame의 pagenum을 의미한다. 저번 게시물에서 설명했듯이, pagenum은 disk상의 offset에 해당한다.

- is_dirty, is_pinned: 위에서 설명했듯이, 수정이 있었는지(id_dirty), 현재 사용중에 있는지(is_pinned)를 알려주는 변수이다.

-next of LRU, prev of LRU: LRU알고리즘을 구현하는 포인터이다. 

# 끝으로

이렇게 버퍼를 구현하기 위해 알아야 할것들을 알아봤다. 위 정보를 통해 Buffer manager를 구현할 수 있을 것이다. 내가 처음 구현할 때는 이런것도 하나도 이해하지 못했던것 같다. 그러니 모든지 부딪혀보자!!

